# -*- coding: utf-8 -*-
"""big-data-cve.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1enYwJXlhBhr5uV5TErYAvWW2Szt1n2zU
"""

!apt-get -y install openjdk-8-jdk-headless
!wget http://apache.osuosl.org/spark/spark-2.4.0/spark-2.4.0-bin-hadoop2.7.tgz
!tar xf spark-2.4.0-bin-hadoop2.7.tgz
!pip install findspark

import os

# setup environment variables
os.environ["JAVA_HOME"] = '/usr/lib/jvm/java-8-openjdk-amd64'
os.environ["SPARK_HOME"] = '/content/spark-2.4.0-bin-hadoop2.7'
os.environ['KAGGLE_USERNAME'] = 'ronaldsumbayak'
os.environ['KAGGLE_KEY'] = '771009dffffa0cd0883d5fb98594d756'

# download dataset
!kaggle datasets download -d kmader/aminer-academic-citation-dataset
!unzip aminer-academic-citation-dataset.zip -d data

import findspark
findspark.init()

from pyspark.sql import SparkSession, functions as F

spark = SparkSession.builder.master('local[*]').getOrCreate()

from functools import reduce

dblp_refs = [spark.read.json('data/dblp-ref-0.json'),
             spark.read.json('data/dblp-ref-1.json'),
             spark.read.json('data/dblp-ref-2.json'),
             spark.read.json('data/dblp-ref-3.json')]
df = reduce(lambda x, f: f.union(x), dblp_refs)

df.count()

df.show()

annual_paper_count = df.groupBy('year').count().orderBy('year', ascending=False)

annual_paper_count.show()

annual_paper_count.toPandas().plot(x='year', y='count')

n_citation_avg = df.agg(F.avg('n_citation')).collect()[0][0]
print('Average number of citation per paper:', int(n_citation_avg))

yv = df.groupBy('year', 'venue') \
       .count() \
       .where('venue != ""')
ym = df.groupBy('year', 'venue') \
       .count() \
       .where('venue != ""') \
       .groupBy('year') \
       .agg(F.max('count').alias('count'))

vy = ym.join(yv, ['year', 'count'], 'left') \
       .orderBy('year', ascending=False)
vy.show()